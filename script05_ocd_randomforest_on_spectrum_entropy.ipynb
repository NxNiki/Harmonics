{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83c00cce-163b-4ac5-afec-4472c3e74981",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run LASSO on the harmonic features (entropy of the spectrum power histogram)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "## this only returns the accuracy. we use all the data to estimate a single estimator to extract the coefs (with is averaged across the inner cv)\n",
    "from sklearn.model_selection import cross_val_score \n",
    "## to do: we can use cross validate to return estimator for each outer cv.\n",
    "from sklearn.model_selection import cross_validate \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "input_dir = 'ocd_out04_power_histogram_and_entropy'\n",
    "output_dir = 'ocd_out05_randomforest'\n",
    "cv_outer = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18c3bd62-bc78-4f63-932c-01d76f0eedbe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_00.csv\n",
      "group\n",
      "hc     45\n",
      "ocd    35\n",
      "dtype: int64\n",
      "cross validaton result, mean 0.662500, std: 0.050000\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_01.csv\n",
      "cross validaton result, mean 0.587500, std: 0.134629\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_02.csv\n",
      "cross validaton result, mean 0.537500, std: 0.063738\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_03.csv\n",
      "cross validaton result, mean 0.575000, std: 0.061237\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_04.csv\n",
      "cross validaton result, mean 0.525000, std: 0.084779\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_05.csv\n",
      "cross validaton result, mean 0.512500, std: 0.072887\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_06.csv\n",
      "cross validaton result, mean 0.512500, std: 0.155121\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_07.csv\n",
      "cross validaton result, mean 0.537500, std: 0.122474\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_08.csv\n",
      "cross validaton result, mean 0.462500, std: 0.063738\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_09.csv\n",
      "cross validaton result, mean 0.650000, std: 0.075000\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "data_files = glob.glob(input_dir + '/out04_entropy_freq_*.csv')\n",
    "data_files.sort()\n",
    "\n",
    "all_result = []\n",
    "print_group_size = True\n",
    "\n",
    "comparision = [('hc', 'ocd')]\n",
    "result_accuracy = {comp: [] for comp in comparision}\n",
    "result_coefs = {comp: [] for comp in comparision}\n",
    "\n",
    "for f in data_files:\n",
    "    \n",
    "    print(f)\n",
    "    freq = re.search('(.*)_freq_(.*).csv', f).group(2)\n",
    "    data = pd.read_csv(f, index_col = 0)\n",
    "    data.dropna(subset=['group'], inplace = True)\n",
    "    # break\n",
    "    \n",
    "    if print_group_size:\n",
    "        print(data.groupby(['group']).size())\n",
    "        print_group_size = False\n",
    "    \n",
    "    X = data.iloc[:, 1:].values\n",
    "    y = data['group'].map({'hc': 0, 'ocd': 1}).values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    C_values = np.logspace(-3, 3, 30)\n",
    "    \n",
    "    for comp in comparision:\n",
    "        # select data with ad/lmci and cn:    \n",
    "        idx_ad_cn = data['group'].isin(comp)\n",
    "        \n",
    "        ## random forest:\n",
    "        rfc = RandomForestClassifier(random_state=0)\n",
    "        \n",
    "        # param_grid = { \n",
    "        #     'n_estimators': [50, 100],\n",
    "        #     'max_features': ['sqrt'],\n",
    "        #     'max_depth' : [2, 4],\n",
    "        #     'criterion' : ['gini']\n",
    "        # }\n",
    "        \n",
    "        param_grid = { \n",
    "            'n_estimators': [20, 50, 100],\n",
    "            'max_features': ['sqrt', 'log2'],\n",
    "            'max_depth' : [2,3,4],\n",
    "            'criterion' : ['gini', 'entropy']\n",
    "        }\n",
    "        \n",
    "        cv_model = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5, n_jobs = 7)\n",
    "        ## run outer cv:\n",
    "        cv_result = cross_val_score(cv_model, X[idx_ad_cn,:], y[idx_ad_cn], cv = cv_outer)\n",
    "        \n",
    "        print('cross validaton result, mean %3f, std: %3f' % (cv_result.mean(), cv_result.std()))\n",
    "        result_accuracy[comp].append(cv_result)\n",
    "        cv_model.fit(X[idx_ad_cn,:], y[idx_ad_cn])\n",
    "        perm_importance = permutation_importance(cv_model, X[idx_ad_cn,:], y[idx_ad_cn])\n",
    "        result_coefs[comp].append(perm_importance)\n",
    "        \n",
    "    #     break\n",
    "    # break\n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af570e4b-2a9a-4ac6-b78c-3ebfa7692beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save results:\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "for comp in comparision:\n",
    "    res = pd.DataFrame(result_accuracy[comp])\n",
    "    res.columns = ['cv' + str(i) for i in range(1, cv_outer+1)]\n",
    "    res.index = ['freq' + str(i) for i in range(1, 11)]\n",
    "    \n",
    "    res.to_csv(output_dir + '/rf_accuracy_' + comp[0] + '_' + comp[1] + '.csv')\n",
    "    \n",
    "    res = pd.DataFrame(result_coefs[comp])\n",
    "    res.columns = ['roi' + str(i) for i in range(1, 117)]\n",
    "    res.index = ['freq' + str(i) for i in range(1, 11)]\n",
    "    res = res.transpose()\n",
    "    res.to_csv(output_dir + '/rf_coefs_' + comp[0] + '_' + comp[1] + '.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a376c7c-b839-454f-8747-1b442066713a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
