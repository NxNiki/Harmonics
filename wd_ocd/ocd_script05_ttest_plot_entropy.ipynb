{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "514e9952-a98b-4ef3-87f2-d99113341e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot histogram of entropy (grouped by AD diagnosis) for each brain region and frequency.\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import stats\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "\n",
    "output_dir = 'ocd_out05_entropy_histogram/'\n",
    "\n",
    "if not os.path.isdir(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "input_files = glob.glob('ocd_out04_power_histogram_and_entropy/out04_entropy_freq*.csv')\n",
    "input_files.sort()\n",
    "\n",
    "def cohend(d1, d2) -> float:\n",
    "\n",
    "    # calculate the size of samples\n",
    "    n1, n2 = len(d1), len(d2)\n",
    "\n",
    "    # calculate the variance of the samples\n",
    "    s1, s2 = np.var(d1, ddof=1), np.var(d2, ddof=1)\n",
    "\n",
    "    # calculate the pooled standard deviation\n",
    "    s = np.sqrt(((n1 - 1) * s1 + (n2 - 1) * s2) / (n1 + n2 - 2))\n",
    "\n",
    "    # calculate the means of the samples\n",
    "    u1, u2 = np.mean(d1), np.mean(d2)\n",
    "\n",
    "    # return the effect size\n",
    "    return (u1 - u2) / s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49d5d752-8577-48b0-9b05-0109665178da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ocd_out04_power_histogram_and_entropy/out04_entropy_freq_00.csv',\n",
       " 'ocd_out04_power_histogram_and_entropy/out04_entropy_freq_01.csv',\n",
       " 'ocd_out04_power_histogram_and_entropy/out04_entropy_freq_02.csv',\n",
       " 'ocd_out04_power_histogram_and_entropy/out04_entropy_freq_03.csv',\n",
       " 'ocd_out04_power_histogram_and_entropy/out04_entropy_freq_04.csv',\n",
       " 'ocd_out04_power_histogram_and_entropy/out04_entropy_freq_05.csv',\n",
       " 'ocd_out04_power_histogram_and_entropy/out04_entropy_freq_06.csv',\n",
       " 'ocd_out04_power_histogram_and_entropy/out04_entropy_freq_07.csv',\n",
       " 'ocd_out04_power_histogram_and_entropy/out04_entropy_freq_08.csv',\n",
       " 'ocd_out04_power_histogram_and_entropy/out04_entropy_freq_09.csv']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5281458-a7b9-46ab-9b70-7c3e88fa4029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_00.csv\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_01.csv\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_02.csv\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_03.csv\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_04.csv\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_05.csv\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_06.csv\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_07.csv\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_08.csv\n",
      "ocd_out04_power_histogram_and_entropy/out04_entropy_freq_09.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc = {'figure.figsize':(20,8)})\n",
    "sns.set_style(\"whitegrid\", {'axes.grid': False})\n",
    "        \n",
    "num_roi = 116\n",
    "\n",
    "## as we selected the frist session as test set (subjects in current files), we use DX_bl as the diagnosis.\n",
    "## but it seems DX_bl and DX are identical...\n",
    "\n",
    "column_index = pd.MultiIndex.from_product([[i for i in range(num_roi)], ['p value', 'cohen''s d']])\n",
    "row_index = np.arange(len(input_files))\n",
    "result_table = pd.DataFrame(index = row_index, columns = column_index)\n",
    "result_table.index.name = 'wavelet frequency'    \n",
    "\n",
    "result_table_emci = result_table.copy()\n",
    "\n",
    "for f in input_files:\n",
    "    print(f)\n",
    "    freq = re.search('(.*)_freq_(.*).csv', f).group(2)\n",
    "    data = pd.read_csv(f, index_col = 0)\n",
    "    \n",
    "    for roi in range(num_roi):\n",
    "        \n",
    "        # plot histogram of entropy grouped by DX_bl (AD diagnosis at baseline).\n",
    "        entropy = data[['group', str(roi)]]\n",
    "        #entropy = entropy[entropy['DX_bl'].isin(['CN', 'AD', 'EMCI'])]\n",
    "        n_sample = entropy.groupby('group').count()[str(roi)].min()\n",
    "        entropy = entropy.groupby(\"group\").sample(n=n_sample, random_state=1)\n",
    "        \n",
    "        # plot histogram of selected roi and frequency.\n",
    "        if roi % 50 == 0 and int(freq) % 3 == 0:\n",
    "            ax = sns.histplot(entropy, x=str(roi), hue=\"group\", element=\"step\")\n",
    "            sns.move_legend(ax, \"upper left\")\n",
    "\n",
    "            figure_name = 'entropy_histogram_freq_' + freq + '_roi_' + str(roi) + '.png'\n",
    "            plt.savefig(output_dir + figure_name)\n",
    "            plt.clf()\n",
    "    \n",
    "        # t-test between OCD and CN for each roi and frequency: \n",
    "        ad = entropy.query('group == \"hc\"')[str(roi)]\n",
    "        cn = entropy.query('group == \"ocd\"')[str(roi)]\n",
    "        ttest = stats.ttest_ind(ad, cn, permutations=10000, random_state=rng)\n",
    "        result_table.loc[int(freq), (roi, 'p value')] = ttest.pvalue\n",
    "        result_table.loc[int(freq), (roi, 'cohen''s d')] = cohend(ad, cn)\n",
    "        \n",
    "     \n",
    "        # break\n",
    "\n",
    "    ## line plot of mean values across subject of entropy for each frequency.\n",
    "    ## x: roi index\n",
    "    ## y: entropy\n",
    "    \n",
    "    ## selected groups to be displayed. add by xin May-04-2022.\n",
    "    \n",
    "    data_mean = data.groupby('group').mean().reset_index()\n",
    "    data_mean = pd.melt(data_mean, id_vars = ['group'], value_vars = [str(i) for i in range(num_roi)])\n",
    "    data_mean\n",
    "\n",
    "    p = sns.lineplot(data=data_mean, x=\"variable\", y=\"value\", hue=\"group\")\n",
    "    p.set_xlabel(\"roi index\", fontsize = 20)\n",
    "    p.set_ylabel(\"mean entropy across subjects\", fontsize = 20)\n",
    "\n",
    "    # only show every 10 roi index.\n",
    "    ax = plt.gca()\n",
    "    temp = ax.xaxis.get_ticklabels()\n",
    "    temp = list(set(temp) - set(temp[::10]))\n",
    "\n",
    "    for label in temp:\n",
    "        label.set_visible(False)\n",
    "\n",
    "    figure_name = 'entropy_mean_freq_' + freq + '.png'\n",
    "    plt.savefig(output_dir + figure_name)\n",
    "    plt.clf()\n",
    "    \n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48164e-de9c-4102-b036-0402695a2bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([data[['ocd', 'subject_id']].groupby('group').count()], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b57490-1971-403f-8cbf-137f8538b904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_stars(report, start_col = 0):\n",
    "    \n",
    "    cols = slice(0,None,2)\n",
    "    report2 = report.copy()\n",
    "    \n",
    "    report2.iloc[:, cols] = report2.iloc[:, cols].astype(float).round(3)\n",
    "    # report.iloc[:,1:]=report.iloc[:,1:].mask(report.iloc[:,1:].le(0.05), report.astype(str).apply(lambda x : x.str[:5]).add('*'))\n",
    "\n",
    "    report2.loc[:,:] = report2.loc[:,:].astype(str).apply(lambda x : x.str[:5]).apply(lambda x : x.str.ljust(5, fillchar='0'))\n",
    "\n",
    "    report2[report.iloc[:, cols].le(0.05)] = report2[\n",
    "        report.iloc[:, cols].le(0.05)].astype(str).apply(lambda x : x.str[:5]).add('*')\n",
    "\n",
    "    report2[report.iloc[:, cols].le(0.01)] = report2[\n",
    "        report.iloc[:, cols].le(0.01)].astype(str).apply(lambda x : x.str[:5]).add('**')\n",
    "\n",
    "    # report2[report.iloc[:,skip_col:].le(0.001)] = report2[\n",
    "    #     report.iloc[:,skip_col:].le(0.001)].astype(str).apply(lambda x : x.str[:5]).add('***')\n",
    "    report2[report.iloc[:, cols].le(0.001)] = '<.001***'\n",
    "    \n",
    "    return report2\n",
    "    \n",
    "report = add_stars(result_table, start_col = 0)\n",
    "report.transpose().to_csv(output_dir + 'ttest_entropy_ad.csv')\n",
    "\n",
    "report_emci = add_stars(result_table_emci, start_col = 0)\n",
    "report_emci.transpose().to_csv(output_dir + 'ttest_entropy_emci.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f34e45-bb3d-4cd7-8a3a-54656099ed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_emci.iloc[:,::2].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e047b-d8b5-4227-8e13-0bd6ad208aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.iloc[:,::2].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c51195-dfea-45a0-8854-34006745fe03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
