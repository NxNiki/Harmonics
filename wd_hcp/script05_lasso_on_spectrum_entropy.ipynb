{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83c00cce-163b-4ac5-afec-4472c3e74981",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run LASSO on the harmonic features (entropy of the spectrum power histogram)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "## this only returns the accuracy. we use all the data to estimate a single estimator to extract the coefs (with is averaged across the inner cv)\n",
    "from sklearn.model_selection import cross_val_score \n",
    "## to do: we can use cross validate to return estimator for each outer cv.\n",
    "from sklearn.model_selection import cross_validate \n",
    "\n",
    "input_dir = 'hcp_out04_power_histogram_and_entropy_0back'\n",
    "input_dir2 = 'hcp_out04_power_histogram_and_entropy_2back'\n",
    "\n",
    "output_dir = 'out05_lasso'\n",
    "cv_outer = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18c3bd62-bc78-4f63-932c-01d76f0eedbe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_00.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_00.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.573000, std: 0.019325\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_01.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_01.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.554217, std: 0.013773\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_02.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_02.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.583430, std: 0.022788\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_03.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_03.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.562568, std: 0.014028\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_04.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_04.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.555811, std: 0.027422\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_05.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_05.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.573539, std: 0.023982\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_06.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_06.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.564129, std: 0.012257\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_07.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_07.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.605842, std: 0.016434\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_08.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_08.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.605331, std: 0.014918\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_09.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_09.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.558960, std: 0.036019\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "data_files = glob.glob(input_dir + '/out04_entropy__freq_*.csv')\n",
    "data_files.sort()\n",
    "\n",
    "data_files2 = glob.glob(input_dir2 + '/out04_entropy__freq_*.csv')\n",
    "data_files2.sort()\n",
    "\n",
    "result_accuracy = []\n",
    "result_coefs = []\n",
    "print_group_size = True\n",
    "\n",
    "for f1, f2 in zip(data_files, data_files2):\n",
    "    \n",
    "    print(f1)\n",
    "    print(f2)\n",
    "    \n",
    "    freq = re.search('(.*)_freq_(.*).csv', f1).group(2)\n",
    "    data = pd.read_csv(f1, index_col = None, header = None)\n",
    "    data2= pd.read_csv(f2, index_col = None, header = None)\n",
    "    \n",
    "    num1 = data.shape[0]\n",
    "    num2 = data2.shape[0]\n",
    "    \n",
    "    if print_group_size:\n",
    "        print(num1)\n",
    "        print(num2)\n",
    "    \n",
    "    X = pd.concat([data, data2], axis = 0, ignore_index = False).values\n",
    "    y = np.hstack((np.ones((num1)), np.zeros((num2))))\n",
    "    \n",
    "    # break\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    C_values = np.logspace(-2, 3, 10)\n",
    "    \n",
    "\n",
    "    # build lassoCV that tune parameters with inner cv:\n",
    "    # reg = LogisticRegressionCV(cv = 5, random_state=0, Cs = C_values, n_jobs = 5,\n",
    "    #                            penalty = 'l1', solver='liblinear').fit(X[idx_ad_cn,:], y[idx_ad_cn])\n",
    "\n",
    "    reg = LogisticRegressionCV(cv = 5, random_state=0, Cs = C_values, n_jobs = 5,\n",
    "                               penalty = 'l1', solver = 'liblinear')\n",
    "\n",
    "    # reg = LassoCV(cv=5, random_state=0, normalize = True, tol = .001).fit(X[idx_ad_cn,:], y[idx_ad_cn])\n",
    "    # run outer cv:\n",
    "    cv_result = cross_val_score(reg, X, y, cv = cv_outer)\n",
    "    print('cross validaton result, mean %3f, std: %3f' % (cv_result.mean(), cv_result.std()))\n",
    "    result_accuracy.append(cv_result)\n",
    "\n",
    "    reg = LogisticRegressionCV(cv = 5, random_state=0, Cs = C_values, n_jobs = 5,\n",
    "                               penalty = 'l1', solver = 'liblinear').fit(X, y)\n",
    "    result_coefs.append(reg.coef_.reshape(-1))\n",
    "        \n",
    "    #     break\n",
    "    # break\n",
    "\n",
    "print('finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "39b4120a-7999-4b8a-ba15-9726c7072682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.58333333, 0.55729167, 0.56510417, 0.60574413, 0.5535248 ]),\n",
       " array([0.54166667, 0.58072917, 0.55208333, 0.55091384, 0.54569191]),\n",
       " array([0.61458333, 0.54947917, 0.56770833, 0.59791123, 0.58746736]),\n",
       " array([0.5703125 , 0.54166667, 0.5703125 , 0.55091384, 0.57963446]),\n",
       " array([0.56770833, 0.50520833, 0.54947917, 0.57963446, 0.5770235 ]),\n",
       " array([0.5546875 , 0.5390625 , 0.578125  , 0.60574413, 0.59007833]),\n",
       " array([0.578125  , 0.5703125 , 0.54427083, 0.55613577, 0.57180157]),\n",
       " array([0.61197917, 0.57552083, 0.625     , 0.61096606, 0.60574413]),\n",
       " array([0.59895833, 0.58333333, 0.609375  , 0.60574413, 0.62924282]),\n",
       " array([0.54166667, 0.52604167, 0.5234375 , 0.5926893 , 0.61096606])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af570e4b-2a9a-4ac6-b78c-3ebfa7692beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save results:\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "\n",
    "res = pd.DataFrame(result_accuracy)\n",
    "res.columns = ['cv' + str(i) for i in range(1, cv_outer+1)]\n",
    "res.index = ['freq' + str(i) for i in range(1, 11)]\n",
    "\n",
    "res.to_csv(output_dir + '/lasso_accuracy_0back_2back.csv')\n",
    "\n",
    "res = pd.DataFrame(result_coefs)\n",
    "res = res.transpose()\n",
    "res.index = [i for i in range(1, 269)]\n",
    "res.columns = ['freq' + str(i) for i in range(1, 11)]\n",
    "\n",
    "res.to_csv(output_dir + '/lasso_coefs_0back_2back.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
