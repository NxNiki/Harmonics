{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c00cce-163b-4ac5-afec-4472c3e74981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## run LASSO on the harmonic features (entropy of the spectrum power histogram)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "## this only returns the accuracy. we use all the data to estimate a single estimator to extract the coefs \n",
    "# (which is averaged across the inner cv)\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "## to do: we can use cross validate to return estimator for each outer cv.\n",
    "from sklearn.model_selection import cross_validate \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "input_dir  = 'hcp_out04_power_histogram_and_entropy_0back'\n",
    "input_dir2 = 'hcp_out04_power_histogram_and_entropy_2back'\n",
    "\n",
    "# output_dir = 'hcp_out05_randomforest'\n",
    "output_dir = 'hcp_out05_adaboost'\n",
    "cv_outer   = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c3bd62-bc78-4f63-932c-01d76f0eedbe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_00.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_00.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.557350, std: 0.019898\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_01.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_01.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.534412, std: 0.020676\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_02.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_02.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.563596, std: 0.020628\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_03.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_03.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.535460, std: 0.009329\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_04.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_04.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.519274, std: 0.018029\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_05.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_05.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.549531, std: 0.014096\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_06.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_06.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.539105, std: 0.008215\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_07.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_07.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.553703, std: 0.014269\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_08.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_08.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.558949, std: 0.026919\n",
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_09.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_09.csv\n",
      "959\n",
      "959\n",
      "cross validaton result, mean 0.525552, std: 0.019379\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "data_files = glob.glob(input_dir + '/out04_entropy__freq_*.csv')\n",
    "data_files.sort()\n",
    "\n",
    "data_files2 = glob.glob(input_dir2 + '/out04_entropy__freq_*.csv')\n",
    "data_files2.sort()\n",
    "\n",
    "result_accuracy = []\n",
    "result_coefs = []\n",
    "print_group_size = True\n",
    "\n",
    "for f1, f2 in zip(data_files, data_files2):\n",
    "    \n",
    "    print(f1)\n",
    "    print(f2)\n",
    "    \n",
    "    freq = re.search('(.*)_freq_(.*).csv', f1).group(2)\n",
    "    data = pd.read_csv(f1, index_col = None, header = None)\n",
    "    data2= pd.read_csv(f2, index_col = None, header = None)\n",
    "    \n",
    "    num1 = data.shape[0]\n",
    "    num2 = data2.shape[0]\n",
    "    \n",
    "    if print_group_size:\n",
    "        print(num1)\n",
    "        print(num2)\n",
    "    \n",
    "    X = pd.concat([data, data2], axis = 0, ignore_index = False).values\n",
    "    y = np.hstack((np.ones((num1)), np.zeros((num2))))\n",
    "    \n",
    "    # break\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    C_values = np.logspace(-2, 3, 10)\n",
    "    \n",
    "    clf = AdaBoostClassifier(n_estimators=100, random_state = 0)\n",
    "    param_grid = { \n",
    "        'n_estimators': [20, 50, 100, 200]\n",
    "    }\n",
    "    \n",
    "    cv_model = GridSearchCV(estimator=clf, param_grid=param_grid, cv= 5, n_jobs = 2, refit = True, return_train_score = True)\n",
    "    \n",
    "    # run this to selected tuning parameters, and permutation importance:\n",
    "    cv_model.fit(X, y)\n",
    "    #print(cv_model.cv_results_)\n",
    "    \n",
    "    ## run outer cv to get prediction accuracy:\n",
    "    cv_result = cross_val_score(cv_model, X, y, cv = cv_outer)\n",
    "    \n",
    "    print('cross validaton result, mean %3f, std: %3f' % (cv_result.mean(), cv_result.std()))\n",
    "    result_accuracy.append(cv_result)\n",
    "    # cv_model.fit(X, y)\n",
    "    perm_importance = permutation_importance(cv_model, X, y)\n",
    "    result_coefs.append(perm_importance['importances_mean'])\n",
    "    \n",
    "    # break\n",
    "    \n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb85cdc1-868a-47c2-b8ef-95dbacf55016",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_result_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcv_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_result_\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_result_'"
     ]
    }
   ],
   "source": [
    "cv_model.cv_result_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af570e4b-2a9a-4ac6-b78c-3ebfa7692beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save results:\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "\n",
    "res = pd.DataFrame(result_accuracy)\n",
    "res.columns = ['cv' + str(i) for i in range(1, cv_outer+1)]\n",
    "res.index = ['freq' + str(i) for i in range(1, 11)]\n",
    "\n",
    "res.to_csv(output_dir + '/ada_accuracy_.csv')\n",
    "\n",
    "res = pd.DataFrame(result_coefs)\n",
    "res.columns = ['roi' + str(i) for i in range(1, 269)]\n",
    "res.index = ['freq' + str(i) for i in range(1, 11)]\n",
    "res = res.transpose()\n",
    "res.to_csv(output_dir + '/ada_coefs_.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a376c7c-b839-454f-8747-1b442066713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f5fa8-0fd4-4fb3-81cc-7c0010a6afd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3aae5e-fc78-4a7f-91a4-24ab1b504f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
