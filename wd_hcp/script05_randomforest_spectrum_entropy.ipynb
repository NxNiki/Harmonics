{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83c00cce-163b-4ac5-afec-4472c3e74981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## run LASSO on the harmonic features (entropy of the spectrum power histogram)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "## this only returns the accuracy. we use all the data to estimate a single estimator to extract the coefs \n",
    "# (which is averaged across the inner cv)\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "## to do: we can use cross validate to return estimator for each outer cv.\n",
    "from sklearn.model_selection import cross_validate \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "input_dir  = 'hcp_out04_power_histogram_and_entropy_0back'\n",
    "input_dir2 = 'hcp_out04_power_histogram_and_entropy_2back'\n",
    "\n",
    "output_dir = 'hcp_out05_randomforest'\n",
    "cv_outer   = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18c3bd62-bc78-4f63-932c-01d76f0eedbe",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hcp_out04_power_histogram_and_entropy_0back/out04_entropy__freq_00.csv\n",
      "hcp_out04_power_histogram_and_entropy_2back/out04_entropy__freq_00.csv\n",
      "959\n",
      "959\n",
      "mean train score: 0.776474\n",
      "cross validaton result, mean 0.586547, std: 0.011769\n",
      "mean train score: 0.787044\n",
      "cross validaton result, mean 0.561543, std: 0.027646\n",
      "mean train score: 0.772699\n",
      "cross validaton result, mean 0.596985, std: 0.014810\n",
      "mean train score: 0.783159\n",
      "cross validaton result, mean 0.588120, std: 0.016229\n",
      "mean train score: 0.764486\n",
      "cross validaton result, mean 0.561534, std: 0.020149\n",
      "mean train score: 0.792028\n",
      "cross validaton result, mean 0.561018, std: 0.016662\n",
      "mean train score: 0.774366\n",
      "cross validaton result, mean 0.592279, std: 0.023272\n",
      "mean train score: 0.764981\n",
      "cross validaton result, mean 0.598023, std: 0.013596\n",
      "mean train score: 0.693751\n",
      "cross validaton result, mean 0.597004, std: 0.025240\n",
      "mean train score: 0.783009\n",
      "cross validaton result, mean 0.560481, std: 0.010827\n",
      "finished!\n"
     ]
    }
   ],
   "source": [
    "data_files = glob.glob(input_dir + '/out04_entropy__freq_*.csv')\n",
    "data_files.sort()\n",
    "\n",
    "data_files2 = glob.glob(input_dir2 + '/out04_entropy__freq_*.csv')\n",
    "data_files2.sort()\n",
    "\n",
    "result_accuracy = []\n",
    "result_coefs = []\n",
    "print_info = True\n",
    "\n",
    "for f1, f2 in zip(data_files, data_files2):\n",
    "    \n",
    "    freq = re.search('(.*)_freq_(.*).csv', f1).group(2)\n",
    "    data = pd.read_csv(f1, index_col = None, header = None)\n",
    "    data2= pd.read_csv(f2, index_col = None, header = None)\n",
    "    \n",
    "    num1 = data.shape[0]\n",
    "    num2 = data2.shape[0]\n",
    "    \n",
    "    if print_info:\n",
    "        print(f1)\n",
    "        print(f2)\n",
    "        \n",
    "        print(num1)\n",
    "        print(num2)\n",
    "        print_info = False\n",
    "    \n",
    "    X = pd.concat([data, data2], axis = 0, ignore_index = False).values\n",
    "    y = np.hstack((np.ones((num1)), np.zeros((num2))))\n",
    "    \n",
    "    # break\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    C_values = np.logspace(-2, 3, 10)\n",
    "\n",
    "    ## random forest:\n",
    "    rfc = RandomForestClassifier(random_state=0)\n",
    " \n",
    "    # param_grid = { \n",
    "    #     'n_estimators': [50, 100],\n",
    "    #     'max_features': ['sqrt'],\n",
    "    #     'max_depth' : [2, 4],\n",
    "    #     'criterion' : ['gini']\n",
    "    # }\n",
    "\n",
    "    param_grid = { \n",
    "        'n_estimators': [20, 50, 100],\n",
    "        'max_features': [5, 10, 20, 50], #['sqrt', 'log2'],\n",
    "        'max_depth' : [2,3,4],\n",
    "        'criterion' : ['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "    cv_model = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5, n_jobs = 2, refit = True, return_train_score = True)\n",
    "    cv_model.fit(X, y)\n",
    "\n",
    "    ## run outer cv to get prediction accuracy:\n",
    "    # cv_result = cross_val_score(cv_model.best_estimator_, X, y, cv = cv_outer)\n",
    "    cv_result = cross_validate(cv_model.best_estimator_, X, y, cv = cv_outer)\n",
    "    \n",
    "    print('mean train score: %3f' % cv_model.cv_results_['mean_train_score'].mean())\n",
    "    print('cross validaton result, mean %3f, std: %3f' % (cv_result['test_score'].mean(), cv_result['test_score'].std()))\n",
    "    result_accuracy.append(cv_result['test_score'])\n",
    "\n",
    "    perm_importance = permutation_importance(cv_model, X, y)\n",
    "    result_coefs.append(perm_importance['importances_mean'])\n",
    "    \n",
    "    # break\n",
    "    \n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af570e4b-2a9a-4ac6-b78c-3ebfa7692beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save results:\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "\n",
    "res = pd.DataFrame(result_accuracy)\n",
    "res.columns = ['cv' + str(i) for i in range(1, cv_outer+1)]\n",
    "res.index = ['freq' + str(i) for i in range(1, 11)]\n",
    "\n",
    "res.to_csv(output_dir + '/rf_accuracy_.csv')\n",
    "\n",
    "res = pd.DataFrame(result_coefs)\n",
    "res.columns = ['roi' + str(i) for i in range(1, 269)]\n",
    "res.index = ['freq' + str(i) for i in range(1, 11)]\n",
    "res = res.transpose()\n",
    "res.to_csv(output_dir + '/rf_coefs_.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a376c7c-b839-454f-8747-1b442066713a",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367f5fa8-0fd4-4fb3-81cc-7c0010a6afd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120bd5e-a74f-4b09-a3c6-d38a063ab9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
